## AI 시대: 결정, 책임, 경험, 소통 - GPT 버전


### 0. 인사 & 문제 제기

안녕하세요. 반갑습니다. 테오입니다.

또 AI 이야기입니다. 지겹죠? 그런데 어쩔 수 없습니다.
여러분이 이제 막 수료를 하고, 본격적으로 AI와 함께 커리어를 시작하게 되는 세대라서요.

지난 시간에는
“왜 AI가 구조적으로 개발자를 완전히 대체할 수 없는가”
라는 이야기를 했다면,

오늘은 그 다음 단계입니다.

> “그래서 알겠고…
> 그러면 **우리는 무엇을 해야 하느냐?
> AI가 나보다 코딩도 잘하는 것 같은데,
> 나는 뭘 더 할 수 있어야 하지?”

이 질문에 대해, 조금 더 **실천적인 얘기**를 해보려고 합니다.

솔직하게 말하면, 저 같은 시니어 개발자들에게 AI는 굉장히 훌륭한 도구입니다.
나쁘지 않고, 꽤 쿨한 도구입니다. 써먹을 것도 많고, 할 수 있는 것도 많죠.

그런데, **지금 막 배우는 사람들 입장**에서는 조금 다르게 느껴질 수 있어요.
AI를 학습 도구로 쓰다 보면 이런 생각이 듭니다.

> “코딩은 얘가 나보다 잘하는데,
> 나는 왜 이걸 힘들게 배우고 있지?”
> “내가 언젠가 얘보다 잘할 수 있긴 한가?”

현업에 있는 사람은 “AI가 잘하는 영역 / 못하는 영역”이 대충 보입니다.
“이건 얘 시키고, 이건 내가 한다”가 몸으로 와요.

그런데 **처음부터 AI와 같이 배우는 사람**은 오히려 혼란스럽습니다.
그래서 오늘의 핵심은 이겁니다.

> “AI가 잘하는 것보다,
> **AI가 못하는 것**을 중심으로
> 내 역할을 다시 정의해보자.”

---

### 1. 전제: 지금의 AI는 어떤 구조인가?

먼저, AI를 조금 “공학적으로” 정의해보겠습니다.

지금 우리가 쓰는 LLM 계열 AI는 한 줄로 요약하면 이래요.

> **“이미 주어진 입력(텍스트)을 받으면,
> 과거 데이터에서 본 패턴을 이용해
> 그럴듯한 출력을 만들어내는 도구”**입니다.

여기서 중요한 특징이 몇 가지 있습니다.

1. **입력 안에서만 움직인다**

    * AI는 스스로 “이게 진짜 중요한 문제다”라고
      문제의 틀을 바꾸지 않습니다.
    * 우리가 준 프롬프트, 우리가 정한 방향 안에서만 답합니다.

2. **과거 패턴을 흉내 낼 뿐, 자기 목표는 없다**

    * AI의 “목표”는
      우리가 학습시킬 때 정의한 손실 함수, 정책, 안전 규칙입니다.
    * “이번 프로젝트는 단기 성과보다 팀 번아웃을 줄이는 게 중요해.”
      이런 **자기만의 목표, 가치관**이 없습니다.

3. **현실 세계와 직접 연결된 리스크가 없다**

    * 잘못된 답을 해도, AI는 해고되지 않습니다.
    * 평판도 안 떨어지고, 연봉도 안 깎입니다.
    * **결과의 후폭풍이 몸에 닿지 않는 존재**입니다.

또 하나 중요한 점이 있습니다.

> AI에게는 **의도**가 없습니다.

우리가 일부러 그렇게 설계했습니다.

AI가 “자기 의도”를 갖게 되면,
무엇을 중요하게 여기고, 어디로 가려고 하고,
어떤 행동을 스스로 택할지 통제하기 어려워집니다.

여러분 스카이넷 아시죠?
터미네이터에서 나오는 그 친구.

실제 현실에서도,
“의도를 가진 AI 시스템”은
안전·통제·책임 문제를 감당하기가 너무 어렵습니다.

그래서 현재 상용 AI 시스템들은
**의도 없이**,
**세션 단위로 끊겨서**,
**입력 → 출력 패턴 생성기**로 설계돼 있습니다.

이게 오늘 이야기의 “전제”입니다.

---

### 2. 정의: 인간의 “문제 해결”을 이루는 네 가지 역할

이제 인간 쪽으로 와봅시다.

우리가 “문제 해결을 잘한다”라고 말할 때,
그 안에는 어떤 요소들이 들어갈까요?

저는 네 가지로 나눠 보려고 합니다.

1. **결정**

    * 여러 옵션 중 **무엇을 얻기 위해 무엇을 포기할지** 고르는 것
    * 기술 선택, 구조 선택, 우선순위, 일정 조정… 전부 결정입니다.

2. **책임**

    * “그때 왜 그렇게 했는지” 설명하고,
    * 그 결과(성공/실패)에 대한 후폭풍을 **몸으로 감당하는 것**.

3. **경험**

    * 같은 맥락에서
      여러 번 **결정–실행–결과**를 반복하면서 쌓이는 패턴.
    * “이런 문제는 보통 이런 식으로 풀리더라”라는 감각.

4. **소통**

    * 이 모든 것을 다른 사람·조직·AI에게
      **구체적·구조적·인과적으로 설명해서**,
      같은 문제를 같은 구조로 보게 만드는 것.

그리고 이 네 가지의 맨 바닥에는 항상 하나가 깔려 있습니다.

> **의도**
> “나는 무엇을 중요하게 여기고,
> 무엇을 만들고 싶고,
> 무엇을 감수할 각오가 되어 있는가.”

이제, 아까 전제를 여기다 대입해 봅시다.

---

### 3. 귀결 1: 왜 AI는 이 네 가지를 구조적으로 잘하지 못하는가?

#### 3-1. AI는 “결정”을 할 수 없다

AI는 **옵션을 나열**하고, **장단점을 비교**해주는 데는 능숙합니다.
하지만 진짜 결정은 이 순간에 일어납니다.

> “무엇을 얻기 위해 무엇을 포기할지
> 내가 감수하겠다.”

여기에는

* 팀의 상황
* 조직의 목표
* 나의 커리어
* 리스크 감수 수준

이 다 들어갑니다.

AI는:

* 자기 커리어도 없고,
* 해고당하지도 않고,
* 동료와의 관계도 없고,
* 리스크를 감수할 이유도 없습니다.

그래서 할 수 있는 것은

> “이런 상황에서는 보통 사람들이 이런 선택을 많이 했습니다.”

라고 **추천**하는 것까지입니다.

최종 결정은,
**언제나 인간이 자기 이름을 걸고 해야 하는 일**입니다.

---

#### 3-2. AI는 “책임”을 질 수 없다

책임은,

* 결과가 좋든 나쁘든,
* 왜 그렇게 했는지 설명하고,
* 신뢰의 변화를 감당하는 일입니다.

실패하면,

* 상사와 동료의 신뢰가 깎이고,
* 평가가 나빠지고,
* 다음 기회를 잃을 수도 있습니다.

이건 철저히 **세계에 묶여 있는 인간**의 문제입니다.

AI는:

* 신뢰를 잃지도 않고,
* 평가를 받지도 않고,
* 법적·제도적 책임을 지지 않습니다.

그래서 최대한 할 수 있는 일은,

> “당시 로그를 보면 이런 정보를 바탕으로
> 이런 답을 냈었습니다.”

정도입니다.

“책임”은 로그를 남기는 행위가 아니라,
**그 결과를 자기 몫으로 가져오는 행위**입니다.
이건 AI 쪽이 아니라, **여러분 쪽에 묶여 있는 역할**입니다.

---

#### 3-3. AI는 “경험”을 할 수 없다

AI는 엄청난 양의 데이터를 학습합니다.
전 세계 수많은 사람의 과거 코드, 글, 기록이 들어가 있죠.

그래서 **지식**은 우리보다 훨씬 많을 수 있습니다.

하지만 우리가 말하는 **경험**은 이런 겁니다.

> “내가 이 맥락에서 이런 결정을 했더니
> 팀이 이렇게 반응했고,
> 서비스가 이렇게 바뀌었고,
> 내가 이런 감정을 느끼고,
> 그걸 기준으로 다음에는 다르게 했다.”

같은 주체가, 같은 세계에서,
성공과 실패를 반복하며 쌓은 흔적입니다.

지금의 AI는:

* 한 번의 답변이 현실에서 어떤 결과를 냈는지
  **직접 관측하지 못하고**,
* 그걸 기반으로 스스로 정책을 바꾸지도 않고,
* 무엇보다 “내가 잘못해서 이런 피해가 났다”라는
  감정적·사회적 비용을 치르지 않습니다.

AI가 가진 것은 **집단의 데이터**이고,
여러분이 가지게 되는 것은 **개인의 경험**입니다.

이 둘은 전혀 다른 것입니다.

---

#### 3-4. AI는 “소통”을 하지 못한다

많은 분들이 이렇게 느끼실 거예요.

> “아니, 나 지금도 AI랑 대화하고 있는데?
> 이게 소통 아닌가요?”

우리가 오늘 말하는 **소통**은 훨씬 좁고, 더 공학적인 개념입니다.

* **구체적으로**

    * “느려요”가 아니라
    * “이번 주 월~금, 점심 12~1시, 결제 API p95가 7초까지 튭니다.”

* **구조적으로**

    * “이건 인프라 레이어의 캐시 모듈,
      읽기 전용 흐름에서 병목이 생긴 문제입니다.”

* **인과적으로**

    * “여기 캐시 정책을 바꿨더니 응답이 7초 → 3초로 줄었고,
      그 결과 이탈률이 10% → 3%로 내려갔습니다.”

이런 식으로,

> 내가 한 **문제정의–결정–실행–경험**을
> 다른 사람·조직·AI가 다시 재구성할 수 있게
> **언어로 패키징해서 전달하는 것**이 소통입니다.

여기에는 항상

* 상대의 역할·권한·관심,
* 팀의 분위기,
* 지금 이 말을 했을 때 관계가 어떻게 바뀔지

까지 고려하는 **사회적 최적화**가 들어갑니다.

AI는 문장을 예쁘게, 친절하게, 논리적으로 만들어주는 데에는 탁월하지만,
“내가 이 말을 했을 때 앞으로 내 위치와 관계가 어떻게 바뀔지”에 대한 **리스크 감각**이 없습니다.

그래서 AI는 훌륭한 **문장 생성 도구**는 될 수 있지만,
우리가 말하는 의미의 **소통 주체**는 아닙니다.

---

### 4. 중간 정리 – 그래서 인간은 무엇을 맡는가?

여기까지 정리하면, 논리는 자연스럽게 이렇게 이어집니다.

1. 지금의 AI는 **의도 없이, 패턴을 생성하는 도구**다.
2. 문제 해결에는 **결정·책임·경험·소통** 네 가지 역할이 필요하다.
3. 이 네 가지 모두

    * 목표/가치 판단,
    * 결과 귀속,
    * 반복 경험,
    * 관계/맥락을 전제로 한다.
4. 따라서 AI는 이 네 가지를

    * **보조할 수는 있지만**,
    * **온전히 대신할 수는 없다.**

그래서 여러분이 앞으로 하게 될 일은,
AI와 경쟁해서 **코드를 더 잘 치는 사람**이 되는 게 아니라,

> **문제정의–결정–책임–경험–소통**이라는
> 문제 해결의 전체 루프를
> 책임지는 사람이 되는 것입니다.

그러려면, 개발자라는 역할을 다시 정의해 볼 필요가 있습니다.

---

### 5. 개발자 = 인간 ↔ 컴퓨터 사이의 번역가

개발자를 가장 많이 비유하는 말 중 하나가 “번역가”입니다.

> “모호한 인간의 요구사항을
> 컴퓨터가 이해할 수 있는 구조와 코드로 번역하는 사람”

인간 언어와 컴퓨터 언어는 완전히 다릅니다.

* **인간 언어**

    * 추상적이고 모호합니다.
    * 맥락에 의존합니다.
    * “느낌”과 “의도”가 많이 들어가 있습니다.
    * “대충” 말해도 상대가 채워 넣어 주기를 기대합니다.

* **컴퓨터 언어**

    * 0과 1, 메모리, 전기 신호의 세계입니다.
    * 하나라도 틀리면 동작하지 않습니다.
    * 모든 것이 **구체적이고 명확**해야 합니다.
    * 상태와 데이터의 변화가 정확해야 합니다.

인간의 뇌는 용량이 한정돼 있고, 에너지를 많이 씁니다.
그래서 최대한 추상적으로, 압축해서 생각하도록 진화했습니다.

컴퓨터는 그 반대입니다.
**추상적인 요구를 끝까지 구체화해서**
명시적인 데이터와 로직으로 내려야만 돌아갑니다.

그래서 개발이 어렵습니다.

> “막연한 기획서”를
> “구체적인 동작과 데이터 변화”로
> 끝까지 풀어내야 하기 때문입니다.

이게 전통적으로 말하는 **하드 스킬**입니다.
인간의 언어를 컴퓨터 언어로 번역하는 능력.

반대로, 번역은 양방향이죠.

* 컴퓨터에 있는 상태, 로그, 코드, 버그를
* 다시 **사람이 이해할 수 있는 언어로** 설명하는 능력.

이게 우리가 말하는 **소프트 스킬**입니다.

---

### 6. AI 등장 이후 – 번역 구조에 생긴 변화

이제 이 번역 구조 사이에, 새로운 계층이 하나 생겼습니다. 바로 **AI**입니다.

옛날 구조는 단순했습니다.

> 인간 ↔ 개발자 ↔ 컴퓨터

지금은 이렇게 바뀌었습니다.

> 인간 ↔ 개발자 ↔ AI ↔ 컴퓨터

AI는 **하드 스킬의 상당 부분**을 덜어주기 시작했습니다.

* 코드 뼈대 만들기
* 리팩토링 아이디어 내기
* 에러 메시지 분석
* 코드를 요약해서 설명하기

이런 건 AI가 우리가 처음 배울 때보다 훨씬 더 잘해줍니다.

그래서 **하드 스킬의 “허들”**은 분명히 낮아졌습니다.

문제는, 여러분이 지금 **그 하드 스킬 허들을 넘는 시기**에
AI를 같이 보고 있다는 점입니다.

> “AI가 나보다 코드를 잘 치는데,
> 내가 이걸 왜 이렇게 힘들게 배우고 있지?”

라고 느끼기 쉽습니다.

여기서 관점을 하나 바꾸면 좋겠습니다.

> “나는 AI보다 코딩을 잘하는 사람이 되겠다”가 아니라,
> **“나는 AI에게 일을 잘 시키고,
> 그 결과에 책임지는 사람이 되겠다.”**

그러려면, AI에게도, 팀 동료에게도,
**말을 잘해야 합니다.**

그냥 말이 아니라,

> **구체적으로, 구조적으로, 인과적으로 말하는 능력**입니다.

이제 이 세 가지를 자세히 보겠습니다.

---

### 7. 구체적으로, 구조적으로, 인과적으로 말하기

#### 7-1. 왜 “구체적으로” 말해야 하는가?

AI는 기본적으로 **랜덤성을 가진 모델**입니다.
동일한 프롬프트를 주어도,
조금씩 다른 결과를 만들도록 설계되어 있습니다.

이 랜덤성 때문에 생기는 부작용이
우리가 흔히 말하는 “환각”이죠.
심지어 이걸 **Feature**라고 부르기도 합니다.

이 말은 곧,

> “중간에 오해될 여지가 남아 있으면
> AI는 얼마든지 그 틈으로 삐뚤어질 수 있다.”

라는 뜻입니다.

그래서 우리는 **“랜덤하게 튈 수 있는 범위”를 좁혀줘야** 합니다.
그게 바로 구체성입니다.

하지만, 그렇다고 해서

* 처음부터 끝까지 모든 걸 다 적어주고,
* 설계서 수준으로 설명하고,
* 코드 한 줄 한 줄까지 다 지정해줄 거면,

사실 **내가 직접 하는 게 낫습니다**.
굳이 비싼 AI에게 시킬 이유가 없습니다.

그래서 중요한 건,

> “필요한 만큼만,
> 랜덤하게 튈 수 있는 범위가
> 내 의도에서 크게 벗어나지 않을 만큼만
> 구체적으로 말하는 능력”입니다.

이걸 잘 하려면,
반드시 **전체 구조**를 알고 있어야 합니다.

* 어디까지는 내가 정해야 하고,
* 어디부터는 AI가 채워도 괜찮고,
* 어디까지가 내가 책임져야 할 부분인지.

인간의 언어는 보통 **행동과 현상** 중심으로 서술합니다.

> “사용자가 로그인한다.”
> “페이지가 느리다.”
> “에러가 자꾸 난다.”

하지만 컴퓨터 세계에서는
**모든 행동 = 데이터의 변화**입니다.

* 로그인한다
  → 어떤 테이블의 어떤 레코드가 생성/갱신되는가
  → 어떤 토큰이 어디에 저장되는가

그래서 구체적으로 말한다는 것은,

> “행동 묘사”를
> **“데이터와 상태 변화 묘사”**로 바꾸는 것입니다.

---

#### 7-2. 왜 “구조적으로” 말해야 하는가?

구체성이 **양**이라면,
구조는 **좌표**입니다.

아무리 구체적으로 말해도,
그게 **어느 층위의 이야기인지**를 말해주지 않으면
듣는 사람도, AI도 헷갈립니다.

소프트웨어에서 구조를 이야기할 때
대표적인 두 축이 있습니다.

1. **레이어(Layer)**

    * 덜 변하는 것 vs 자주 변하는 것
    * 추상적인 것 vs 구체적인 것
    * 안쪽 레이어 vs 바깥 레이어

2. **모듈(Module)**

    * 같은 목적을 위해 묶여 있는 코드/기능의 단위
    * “이 모듈은 로그인만 책임진다”,
      “이 모듈은 결제만 책임진다” 같은.

현실 세계로 비유하면 이겁니다.

> “한국, 서울, 마포구, 상암동…”
>
> 이런 식으로 레벨이 있으면
> “어디에 가야 하는지”를 찾기 쉽죠.

이처럼, 내가 지금 하는 이야기가

* 시스템 전체 얘기인지,
* 아키텍처 얘기인지,
* 특정 서비스/모듈 얘기인지,
* 특정 함수/쿼리 레벨 얘기인지

항상 **좌표를 찍어 주는 것**이 구조적 말하기입니다.

그래서 구조적으로 말한다는 것은,

> “내가 지금 어느 레이어에서,
> 어느 모듈의,
> 어느 데이터 흐름에 대해
> 이야기하고 있는지”

를 항상 같이 말해주는 것입니다.

---

#### 7-3. 왜 “인과적으로” 말해야 하는가?

인간은 **스토리**를 좋아합니다.

> “왜 이렇게 되었는가?”
>
> “무엇을 했더니,
> 그 다음에 무엇이 어떻게 바뀌었는가?”

이게 인과입니다.

* 앞과 뒤,
* 원인과 결과,
* 의도와 행동과 결과.

재미있는 건, **컴퓨터도 인과를 좋아한다**는 점입니다.

* 어떤 입력이 들어오고,
* 어떤 로직이 실행되고,
* 어떤 출력이 나오는가.

결국 프로그램은
**데이터가 어떤 과정을 통해 어떻게 변했는지**의 이야기입니다.

그래서 인과적으로 말한다는 것은,

> “이 데이터가,
> 이 과정을 거치면서,
> 이런 이유로,
> 이렇게 바뀌었다.”

를 시간 순서대로 설명하는 것입니다.

인간에게는 그게 설명이 되고,
컴퓨터에게는 그게 설계가 됩니다.

---

### 8. 이 세 가지는 어디에 쓰이는가? – 이력서, 면접, 보고, 프롬프트

여기까지 들으면,
“그래, 말이 좋은데… 이걸 어디에 써먹지?”
라는 생각이 들 수 있습니다.

사실, 우리가 이미 하고 있는 거의 모든 것에 다 들어갑니다.

1. **이력서 / 포트폴리오**

    * “내가 무엇을 했는지”를

        * 구체적으로: 어떤 기능, 어떤 결과
        * 구조적으로: 어떤 시스템/팀/역할 안에서
        * 인과적으로: 왜 그렇게 설계/선택했는지
          쓰는 문서입니다.

2. **기술 면접**

    * 면접관이 궁금한 건 결국 이것입니다.

      > “이 사람이
      > 어느 구조를 이해하고 있고,
      > 그 안에서 본인의 선택과 경험을
      > 얼마나 구체·인과적으로 설명할 수 있는가?”

3. **회사에서의 보고 / 협업 / 리뷰**

    * 이슈를 설명할 때,
      “느려요”가 아니라
      “어디서, 언제, 어떤 데이터 흐름에서 느려졌는지”를 말해야 합니다.
    * 설계를 설명할 때도,
      “이게 좋아 보여서요”가 아니라
      “이런 요구와 제약이 있어서, 그래서 이렇게 나누고, 이렇게 흐르게 했습니다”라고
      인과로 설명해야 합니다.

4. **AI에게 일 시키기(프롬프트)**

    * 똑같습니다.

      > “어디 레이어에서,
      > 어떤 모듈의,
      > 어떤 데이터 흐름을,
      > 왜 바꾸려는지”
      > 를 구체·구조·인과적으로 설명해야
      > AI도 제대로 된 답을 줄 수 있습니다.

---

### 9. 그럼 왜 굳이 내가 경험을 해야 하는가? – AI와 성장

여기서 또 하나 중요한 질문이 생깁니다.

> “AI를 쓰면 편하긴 한데,
> 그게 내 성장을 방해하는 건 아닐까?”

많이들 물어봅니다.

저는 이렇게 생각합니다.

AI를 쓰느냐, 쓰지 않느냐가 **성장을 결정하지 않습니다.**

중요한 건,

> “내가 그 과정에서 **온전히 경험을 했느냐**”입니다.

여행으로 비유해 볼게요.

* 혼자 배낭여행을 떠나,
  스스로 계획하고, 길을 잃어보고, 다시 찾는 여행이 있습니다.
* 패키지 여행사를 통하면,
  훨씬 편하고, 안전하고, 더 많은 곳을 볼 수도 있습니다.

둘 다 여행입니다.
둘 다 경험입니다.
방식이 다를 뿐입니다.

반면,

> “나는 집에 있고,
> 다른 사람만 여행을 보내놓고,
> ‘어땠어?’라고 물어보고 듣기만 하는 것”

은 여행 경험이라고 하긴 어렵습니다.

AI도 마찬가지입니다.

* AI를 쓰더라도,
  **내가 직접 결정해 보고,**
  직접 시행착오를 겪어보고,
  왜 그런 결과가 나왔는지를 인과적으로 정리해 보면
  그건 **내 경험**입니다.

* AI에게 다 맡기고,
  결과만 받아서 “오 잘 됐네?” 하고 넘겨버리면,
  그건 **AI의 결과**일 뿐,
  나의 경험으로 쌓이지 않습니다.

경험 없이 지시만 하는 사람은
결국 “현상만 다그치는 사람”이 됩니다.

> “이거 왜 안 돼?”
> “빨리 되게 해.”

개발자는 그런 사람이 되면 안 되겠죠.

그래서 여러분이 지금 교육을 받으면서
직접 코드를 짜보고,
에러도 만나고,
시간도 쓰고,
짜증도 내보고,
끝까지 구현해 보는 겁니다.

AI보다 코딩을 “더” 잘하기 위해서가 아니라,

> 나중에 **지시하고, 결정하고, 책임지고,
> 경험을 쌓고, 소통할 수 있는 사람**이 되기 위해서입니다.

---

### 10. 다시 처음 질문으로

마지막으로, 아까 처음에 던졌던 질문으로 돌아가겠습니다.

> “AI가 나보다 코딩도 잘하는 것 같은데,
> 나는 왜 개발을 배우고 있을까?”

오늘 제가 드리고 싶은 답은 이겁니다.

* 여러분은 **AI보다 코드를 잘 치기 위해서**
  이 과정을 수료한 게 아닙니다.
* 여러분은 앞으로
  **문제를 정의하고,**
  **결정하고,**
  **책임지고,**
  **경험을 쌓고,**
  **사람과 AI에게 소통하는 역할**을 맡게 될 겁니다.
* 그걸 잘하기 위해서,
  개발자다운 생각과 말하기를 훈련하는 겁니다.

그리고 그 개발자다운 말하기는
딱 세 단어로 요약할 수 있습니다.

> **구체적으로, 구조적으로, 인과적으로.**

* 모호한 요구를
  **데이터와 상태 변화**로 구체화하고,
* 구조와 레이어, 모듈, 흐름 위에 올려놓고,
* “왜 그렇게 되었는가, 무엇을 바꾸면 어떻게 달라질까”를
  인과로 설명하는 것.

이걸 할 수 있는 사람이면,

* AI에게도 일을 잘 시킬 수 있고,
* 팀 동료와도 잘 협업할 수 있고,
* 이력서와 면접에서도
  “아, 이 사람은 자기 결정과 경험을 설명할 줄 아는 사람이구나”
  라는 인상을 줄 수 있습니다.

그래서, AI 시대에
여러분이 집중해서 키워야 할 것은

> “AI보다 잘 코딩하는 능력”이 아니라,
> **“AI를 포함해 사람들과 함께
> 문제를 정의하고, 결정하고, 책임지고, 경험하고, 소통하는 능력”**입니다.

그 기반이 되는 것이,

> **구체·구조·인과적 사고와 말하기**입니다.

오늘 강연이,
여러분이 앞으로 공부를 계속할 때

* “내가 지금 구조를 이해하려고 하고 있는가?”
* “내가 지금 왜를 따라가고 있는가?”
* “내가 이 경험을 나중에 설명할 수 있을 만큼
  충분히 깊게 겪고 있는가?”

를 스스로에게 물어볼 수 있는
작은 기준이 되었으면 좋겠습니다.

감사합니다.


#강연

